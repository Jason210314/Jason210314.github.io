(window.webpackJsonp=window.webpackJsonp||[]).push([[36],{444:function(t,s,a){"use strict";a.r(s);var n=a(11),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"简介"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#简介"}},[t._v("#")]),t._v(" 简介")]),t._v(" "),a("p",[t._v("XML 是一种可扩展标记语言，被用来传输和存储数据。它是一种有逻辑的树结构。")]),t._v(" "),a("h2",{attrs:{id:"python-使用-xml-elementtree-解析"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#python-使用-xml-elementtree-解析"}},[t._v("#")]),t._v(" Python 使用 xml.ElementTree 解析")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" xml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("etree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ElementTree "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" ET\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" codecs\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" json\n")])])]),a("p",[a("code",[t._v("codecs")]),t._v("用于打开文件，"),a("code",[t._v("json")]),t._v("用于保存清洗完的数据。")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("tree "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ET"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\t\t"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#获取目录树")]),t._v("\nroot "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getroot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \t"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#得到树根")]),t._v("\nroot "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ET"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fromstring"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\t"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#从字符串直接解析出树根")]),t._v("\n")])])]),a("p",[t._v("获取树根，然后进行操作")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("root"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tag\t\t"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#root元素的标记名")]),t._v("\nroot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("attrib\t\t"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#root元素的属性，为一个dic")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" child "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" root"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\t"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#便利子元素")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("child"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" child"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("attrib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nroot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text \t"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#将元素视为多维数组,用下标访问")]),t._v("\nroot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"element"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text \t"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#找出root下element下的内容字符串")]),t._v("\ntitle "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" root"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Title"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \t"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#获取root元素的title属性")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" neighbor "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" root"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("iter")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'neighbor'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\t"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#遍历所有特定元素,递归到所有，子、孙...元素")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("attrib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" country "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" root"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("findall"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'country'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\t"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#找出所有country元素，仅子代")]),t._v("\n     rank "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" country"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'rank'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text\n     name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" country"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'name'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n     "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" rank"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" country "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" root"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'country'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\t"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#仅找出第一个符合的子代")]),t._v("\n")])])]),a("h1",{attrs:{id:"其他涉及知识"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#其他涉及知识"}},[t._v("#")]),t._v(" 其他涉及知识")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" os\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("mkdir")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\t"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#创建文件夹")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exists"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mkdir"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" son_path "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("listdir"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("root_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\t"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#遍历root_path下的文件")]),t._v("\n\njson"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dic"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" file_obj"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ensure_ascii"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" indent"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" separators"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("','")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("': '")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\t"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#将字典dic输出到文件file_obj中,不对ascii进行编码,缩进4,分隔符为','以及': '")]),t._v("\n")])])]),a("h1",{attrs:{id:"暂时到此"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#暂时到此"}},[t._v("#")]),t._v(" 暂时到此")])])}),[],!1,null,null,null);s.default=e.exports}}]);